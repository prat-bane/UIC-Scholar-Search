<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Coverage-based Data-centric Approaches for Responsible and Trustworthy AI *</title>
				<funder ref="#_agFhPmF">
					<orgName type="full">National Science Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Nima</forename><surname>Shahbazi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Illinois Chicago</orgName>
								<orgName type="institution" key="instit2">University of Illinois Chicago</orgName>
								<orgName type="institution" key="instit3">University of Illinois Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mahdi</forename><surname>Erfanian</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Illinois Chicago</orgName>
								<orgName type="institution" key="instit2">University of Illinois Chicago</orgName>
								<orgName type="institution" key="instit3">University of Illinois Chicago</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Abolfazl</forename><surname>Asudeh</surname></persName>
							<email>asudeh@uic.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Illinois Chicago</orgName>
								<orgName type="institution" key="instit2">University of Illinois Chicago</orgName>
								<orgName type="institution" key="instit3">University of Illinois Chicago</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Coverage-based Data-centric Approaches for Responsible and Trustworthy AI *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8E3D8C0D42C0AA1C54413F5823C73569</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-11-11T02:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The grand goal of data-driven decision systems is to help make decisions easier, more accurate, at a higher scale, and also just. However, data-driven algorithms are only as good as the data they work with. Yet, data sets, especially those with social data, often do not represent minorities. The paucity of training data is a perpetual problem for AI, and the outcome of ML models for cases not represented in their training data is often not reliable. Hence, without properly addressing the lack of representation issues in data, we cannot expect AI-based societal solutions to have responsible and trustworthy outcomes.</p><p>This paper focuses on data coverage as a data-centric approach for identifying and resolving misrepresentation of minorities in data. To achieve this goal, we propose novel algorithms that (a) identify and resolve insufficient data coverage across data with different modalities and (b) use lack of representation information to generate data-centric reliability warnings.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Data-driven decision-making has shaped every corner of human life, spanning from autonomous vehicles to healthcare and even predictive policing and criminal justice. A pivotal concern, especially in applications that affect individuals, revolves around the reliability of the decisions rendered by the system. It is easy to see that the accuracy of a data-driven decision depends, first and foremost, on the data used to make it. Essentially, the system learns the phenomena that data represent. While we may desire that the data should represent the underlying data distribution from which the production data is drawn, this alone may be insufficient, as it merely enables the model to perform well for the average case. As a result, a model with a high accuracy could fail for specific regions in the data with insufficient representation. These regions may matter because they frequently represent some minority population in society. They could also represent cases that may not happen very often but have a relevant impact on the correctness of a critical decision. In short, if the data fails to sufficiently represent a specific population, the outcome of the decision system for that population may not be trustworthy.</p><p>The phenomenon known as Representation Bias can arise from how the data was originally collected, or it could be the result of biases introduced post-collectionÐwhether historically, cognitively, or statistically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Detecting Insufficient Representation of Minorities</head><p>Representation bias happens when the development (training data) population under-represents and subsequently fails to generalize well for some parts of the target population, due to historical bias, sampling bias, etc. The notion of data coverage has been studied across different settings in <ref type="bibr" target="#b1">[2]</ref> as a metric to measure representation bias. At a high level, coverage is referred to as having enough similar entries for each object in a data set. For a better understanding, let us go over the definition of the generalized notion of coverage: Definition 2.1 (Data Coverage) Consider a data set D with n tuples, each consisting of d attributes of interest x = {x 1 , x 2 , • • • , x d }, such as gender, race, salary, age, etc, that are used for coverage identification. The data set also contains target attributes y = {y 1 , • • • , y d ′ } that may or may not be considered for the coverage problem. A query point q is not covered by the data set D, if there are not ªenoughº data points in D that are representative of q. To generalize the notion of coverage, let us define g(q) as the universe of tuples that would represent q and let g D (q) = g(q) ∩ D. In other words, g D (q) are the set of tuples in D that represent q. Using this notation, we define the coverage of q as the size of g D (q). That is, cov(q, D) = |g D (q)|. Given a value τ , q is covered if cov(q, D) &gt; τ . Similarly, a group g is not covered if g ∩ D &lt; τ . The uncovered region in a data set is the collection of groups that are not covered by it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Structured Data</head><p>In this section, we focus on identifying representation bias in structured data. Depending on the type of the attributes of interest, we categorize the techniques into two classes based on whether they target the problem for non-ordinal categorical (e.g. race, gender) or ordinal continuous (e.g. age) attributes. The attributes of interest considered for representation bias often include sensitive attributes such as race and gender but are not necessarily limited to them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Categorical Attributes</head><p>For cases where attributes of interest are non-ordinal categorical, the cartesian product of values on a subset of attributes x ′ ⊆ x, form a set of (sub-)groups. For example, { white male, white female, black male , • • • } are the subgroups defined on the attributes (race,gender). We refer to the number of attributes used to specify a subgroup as the level of that subgroup. For example, the level of the subgroup white male is 2, while the level of the subgroup male is 1. We use ℓ(g), to refer to the level of a subgroup g. Similarly, we say a subgroup g ′ is a subset of g, if the groups specifying g ′ are a superset of the ones for g. For example (married white male) a subset of the more general group (white male). That is, the set of individuals in group (married white male) are a subset of (white male). Moreover, we say a subgroup g is a parent of the subgroup g ′ , if g ′ ⊂ g and ℓ(g) = ℓ(g ′ ) + 1. For example, the subgroup (white male) is a parent of the subgroup (married white male). We use patterns to refer to uncovered subgroups. A pattern P is a string of d values, where P [i] is either a value from the domain of x i , or it is ªunspecifiedº, specified with X. For example, consider a data set with three binary attributes of interest x = {x 1 , x 2 , x 3 }. The pattern P = X01 specifies all the tuples for which x 2 = 0 and x 3 = 1 (x 1 can have any value). The set of patterns that identify most general uncovered subgroups are called Maximal Uncovered Patterns (MUPs).</p><p>No polynomial time algorithm can guarantee the enumeration of the entire MUPs, however, several algorithms inspired by set enumeration and the Apriori algorithm for association rule mining are proposed to efficiently address this problem <ref type="bibr" target="#b0">[1]</ref>. In this regard, we introduce Pattern Graph data structure that exploits the relationship between patterns to do less work than computing all uncovered patterns by removing the non-maximal ones. The parent-child relationship between the patterns is represented in a graph that can be used to find better algorithms. Pattern-Breaker starts from the top of the graph where the general patterns are and moves down by breaking each pattern into more specific ones. If a pattern is uncovered, then all of its descendants are also uncovered and they can not be an MUP, even if they have a parent that is covered. Therefore, this subgraph of the pattern graph can be pruned. The issue with Pattern-Breaker is that it explores the covered regions of the pattern graph and for the cases where there are a few uncovered patterns, it has to explore a large portion of the exponential-size graph. To tackle this, Pattern-Combiner algorithm is proposed that performs a bottom-up traversal of the pattern graph. It uses an observation that the coverage of a node at the level of the pattern graph can be computed as the sum of the coverage values of its children. The problem with Pattern-Combiner is that it traverses over the uncovered nodes first and therefore, it will not perform well for the cases in which most of the nodes in the graph are uncovered. In fact, for the cases where most of the MUPs are placed in the middle of the graph, both Pattern-Breaker and Pattern-Combiner will not be as efficient as they should traverse half of the graph. Therefore, we propose Deep-Diver, a search algorithm based on Depth-First-Search that quickly finds the MUPs, and uses them to limit the search space by pruning the nodes both dominating and dominated by the discovered MUPs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Continuous Attributes</head><p>Data in the real world often consists of a combination of continuous and discrete values. While simple solutions like binning age into young and old can transform the continuous space into discrete. However, they may lead to coarse groupings that are sensitive to the thresholds chosen. It may be inappropriate to treat a 35-yo as young but a 36-yo as old. Therefore, we extend the notion of coverage to continuous space. Particularly, given data set D with n tuples over d attributes, and vicinity radius ρ and coverage threshold k, we want to identify the uncovered region ± the universe of uncovered query points. A query point in continuous data space is covered if there are enough (at least k) data points in its ρ-vicinity neighborhood. ρ-vicinity neighborhood is the circle centered at the query point with radius ρ.</p><p>Depending on the number of attributes in a data set, we propose two algorithms for identifying uncovered regions in data <ref type="bibr" target="#b2">[3]</ref>. The first algorithm known as Uncovered-2D studies coverage over two-dimensional data sets where x = {x 1 , x 2 }. To find the number of circles that a query point falls into and consequently discover   the uncovered region, Uncovered-2D makes a connection to k-th order Voronoi diagrams. Consider a data set D and its corresponding k-th order Voronoi diagram. For every tuple t ∈ D, let • t be the d-dimensional sphere (d-sphere) with radius ρ centered at t. Consider a k-voronoi cell V(S) in the k-th order Voronoi diagram V k (D). Any point q inside the intersections of the d-spheres of tuples in S, i.e. q ∈ ∩ • t ∀t∈S , is covered, while all other points in the region are uncovered. The algorithm starts by constructing the k-th order Voronoi diagram of the data set and then for each Voronoi cell V(S) in the diagram, it computes the intersection of the circles of the tuples in S and marks the portion of V(S) that falls outside it as uncovered. After identifying the uncovered region, a 2D map of {x 1 , x 2 } value combinations is used to report the region to the user. The algorithm for the 2D case can be extended to the general case by relaxing the assumption on the number of attributes to discover the exact uncovered region, however, due to the curse of dimensionality, the search size space explodes as the number of dimensions increases and as a result, the algorithm will not be practical. Therefore, we propose a randomized approximation algorithm based on the geometric notion of ε-net. Let X be a set and R be a set of subsets of X . A set N ⊂ X is an ε-net for X if for any range r ∈ R, if |r ∩ χ| &gt; ε|χ|, then r contains at least one point of N . The idea, at a high level, is to draw enough random samples from the space of potential query points to form an ε-net. We then label the sampled query points as {-1, +1} depending on whether those are covered or not, and learn the uncovered regions using the samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Image Data</head><p>Many known incidents of machine failures due to the lack of representation were on image data. We consider an image data set with a fixed number of low-cardinality sensitive attributes such as race and gender. It is common that image data sets lack explicit values for sensitive attributes, which are crucial for coverage identification. An image data set is often a collection of images from different domains with little to no information about their domain and which groups they belong to. As a result, even studying coverage over low-cardinality and categorical attributes of interests is challenging in these cases.</p><p>In Figure <ref type="figure" target="#fig_3">4</ref>, we show that due to the issues such machine bias and lack of distribution generalizability, solely relying on state-of-the-art machine learning (ML) techniques fail to effectively identify lack of coverage in image data sets. Therefore, we propose an approach based on combining crowdsouring with ML <ref type="bibr" target="#b3">[4]</ref>. Crowdsourcing is particularly promising for image data, for tasks such as image labeling, which, while challenging for the machine, are "easy" for human beings to conduct with minimal error.</p><p>A key observation that enables a cost-effective crowdsourcing approach is that, while studying coverage, we would only like to find out if there are enough tuples from each subgroup. Suppose a subgroup is covered if there are τ = 100 instances of it in the data set. Assume the (majority) group g 1 contains n 1 ≫ 100 objects in the data set. To verify that g 1 is covered, it is enough for the crowd to discover 100 of those objects, not the entire n 1 . Following this, O(τ ) provides a lower bound on the number of crowd tasks required to verify a given group is covered. Still, this lower bound only holds for the groups that are covered, i.e., there is at least τ of those in the data set. Surprisingly, verifying that a minority group is indeed uncovered is cumbersome, unlike the majority group. This is because even though discovering τ objects from a group is enough for verifying that it is covered, one cannot verify a group is uncovered until there is a chance that the data set might still have enough objects from that group. Thus, assuming a non-zero probability for each unlabeled object to belong to each group, one might need to ask the crowd to label the entire data set before they can confirm that a specific group is uncovered.</p><p>data set classifier accuracy precision on female UTKFace: DeepFace (opencv) 93.56 52.02 (females=200, DeepFace (retinaface) 94.16 56.15 males=2800) BaseCNN 97.6 74.8 UTKFace: DeepFace (opencv) 96.53 8.0 (females=20, DeepFace (retinaface) 96.43 10.09 males=2980) BaseCNN 97.6 21.59 Our idea for addressing this challenge is to design a divide and conquer algorithm that, instead of point queries, uses set queries to iteratively eliminate subsets of data that does not include any object from the given group. At a high level, our idea is to ask a set query from the crowd, inquiring whether the selected set contains at least one object from the given group g. The user may provide two responses (yes/no). Interestingly, in either case, the user response provides valuable information that helps efficiently identify the coverage. If the answer is ªNoº, the set does not include any object from the given group g. As a result, the algorithm can safely prune the set, asking no further questions about it. In particular, for a group that is not covered, one can expect to see no answers on large set queries helping to prune a significant portion of the data set quickly. On the other hand, if the answer is ªyesº, the set contains at least one object from the group g. As a result, the algorithm cannot prune the subset since it can have any number (larger than one) of the objects in g. At first glance, the queries with yes answers do not provide helpful information as the algorithm cannot prune the subset (hence it needs to divide it into smaller subsets). However, a key observation is that the algorithm will only observe a limited number of yes answers before it stops. The reason is that the number of set queries with yes answers provides a lower-bound on the number of objects from g in the data set. As a result, the algorithm can stop as soon as the lower bound reaches τ , knowing that g is covered. The D&amp;C approach verifies the data coverage for a given group, while our goal is to identify the uncovered regions for a given set of sensitive attributes. The next question is how to utilize this algorithm for efficient coverage identification on different scenarios of sensitive attributes, forming intersectional or non-intersectional groups. In particular, how can we find maximal uncovered patterns? Our idea is to apply sampling and aggregate estimation techniques to find the groups that even if merged are likely to still be uncovered. This will help reduce the coverage identification cost by running the D&amp;C approach for the merged groups once.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Resolving Insufficient Representation</head><p>Data integration <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref> and data augmentation [7±10] are considered as the primary solutions for reducing data coverage issues in a data set. Data integration is promising when external sources of data are available. On the other hand, recent advancements in generative AI and foundation models have enabled efficient and effective augmentation of data sets with synthetic data. Therefore, in the following, we review two approaches, one from each category, in the context of lack of coverage resolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Integration</head><p>Data integration is to consolidate data from different sources into a single, unified view. Although it is an effective solution to acquire additional data from different distributions, there are sampling policy and costefficiency concerns that need to be examined. Therefore, Data Distribution Tailoring (DT) introduces data integration techniques for resolving insufficient representation of subgroups in a data set in the most cost-effective manner <ref type="bibr" target="#b4">[5]</ref>. A query to DT consists of a target schema, and a set of group distribution requirements in the form of the minimum counts (e.g., ª1,000 breast cancer monitoring data in Chicago with at least 30% label=positive, and at least 20% black patientsº). Collecting a fresh sample from a data view is costly (monetary, human resources, and/or computation cost) <ref type="bibr" target="#b10">[11]</ref>. Therefore, DT focuses on satisfying the count requirements with minimum cost. Given an input query and a lake of available data sources, the first step is to discover a collection of candidate data views that satisfy the target schema. Each data view v i is a projection-join</p><formula xml:id="formula_0">v i = Π D i1 ▷◁ • • • ▷◁ D ik i ,</formula><p>where D ij is a data set in a given data lake. Let us suppose the data views are already discovered. At a high level, DT follows an iterative approach that at each iteration a data view is selected to be queried. Each query to a data view has a fixed cost and returns a sample that may or may not satisfy the query constraints. The samples that are either not fresh, or do not satisfy the query are discarded. Hence, the essential question towards a cost-effective data integration is what data view to query next. Depending on the available information about the data sources, various techniques may be employed.</p><p>For the cases when the group distributions are known, the process of collecting the target data set is a sequence of iterative steps, where at every step, the algorithm chooses a data view, queries it, and if the obtained tuple contributes to one of the groups for which the count requirement is not yet fulfilled, it is kept, otherwise discarded. To do so, a Dynamic Programming (DP) algorithm is proposed. An optimal source at each iteration minimizes the sum of its sampling cost plus the expected cost of collecting the remaining required groups, based on its sampling outcome. The DP algorithm, however, has a pseudo-polynomial time complexity. Hence, it quickly becomes intractable for cases where the minimum count requirements for the groups are not small. For cases where the (sensitive) attribute of interest is binary, such as (biological) sex={male, female}, and the cost to query data is similar from all sources, it turns out that the optimal strategy is to query the data source with maximum probability of obtaining a sample from the minority group. Expanding the binary-attributes algorithm for non-binary cases, the problem can be modeled as an extension of the ªcoupon collector'sº problem <ref type="bibr" target="#b11">[12]</ref>, where the goal is to collect m i instances from each coupon (group) g i . At each iteration, the coupon collector's algorithm identifies a data view as most promising and queries it. In simple terms, a data view with a smaller query cost and a higher chance of obtaining minority groups is more promising.</p><p>For the cases where the group distributions are unknown, we model DT as a multi-armed bandit problem, where every data view is modeled as an arm. Every arm has an unknown distribution of different groups while pulling an arm (i.e., querying the corresponding data view) has a cost. During various iterations, the algorithms pull the arms in an order that its expected total reward is maximized. Arguing that the reward of obtaining a tuple from a group is proportional to how rare this group is across different data views, we design the reward function based on the expected cost one needs to pay in order to collect a tuple from a specific group. As the bandit strategy, we adopt Upper Confidence Bound (UCB) to balance exploration and exploitation. At every iteration, for every arm, UCB computes confidence intervals for the expected reward and selects the arm with the maximum upper bound of reward to be explored next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Data Augmentation using Foundation Models</head><p>While data integration provides a promising approach for resolving coverage issues in a data set, its effectiveness is limited to the availability of external data sources that are rich enough to find sufficient fresh samples from minority groups. This, however, is not always possible, especially since the minority samples are rare and not easy to obtain. Fortunately, recent advancements in Generative AI and Foundation Models have enabled synthesizing samples that are otherwise challenging to obtain from the real world.</p><p>Therefore, as an alternative approach to data integration, we turn our attention to the Foundation Models and Generative AI for resolving the lack of coverage. Particularly, models such as DALL.E 1 have emerged as powerful tools for generating multi-modal data such as image, audio, and video.</p><p>We formalize the foundation model F as a black-box function with the following inputs, that once queried synthesize an output tuple.</p><p>• Prompt: A natural language description providing instructions on the details of the tuple to be generated.</p><p>For instance, a prompt for image generation might be ªA realistic photo of a white cat running in a backyard.º</p><p>• Guide: In cases where only a prompt is provided, the foundation model uses its imagination to generate the requested tuple. For the previous example, the prompt of a cat image, the breed, size, background, and other details are generated based on the model's imagination. Alternatively, a guide can be provided to influence the generation process. The guide is formalized as a pair (t, m) where t is a tuple and m is a mask specifying which parts of the guide tuple should be changed. Using the cat example, t can be a cat image and m can specify the foreground to be regenerated.</p><p>There are multiple challenges towards effective data set augmentations using foundation models. First, we have to determine the minimal set of synthetic tuples that once added to the original data set, under-representation issues are resolved. Second, the generated images should follow the underlying distribution represented in the input data set. Third, the generated tuples should have high quality and look realistic to a human evaluator. Last but not least, given the (often monetary) cost associated with the queries to the foundation model, we should ensure the cost-effectiveness of the data set repair process. Figure <ref type="figure" target="#fig_4">5</ref> shows the architecture of our system CHAMELEON <ref type="bibr" target="#b12">[13]</ref> for coverage enhancement using DALL-E image generator. To address the first challenge, we define the combinations-selection problem, which minimizes the total number of synthetic tuples for resolving lack of coverage of minorities at the most general level. We show the problem is NP-hard, and propose a greedy approximation algorithm for it. To address the second and third challenges, CHAMELEON follows a rejection sampling strategy. It views each tuple in the data set D as an iid sample from the underlying distribution ξ it represents. It uses the vector representations (embeddings) space to describe the distribution. Then, given a newly generated tuple, it employs the one-class support vector machine (OCSVM) approach proposed by Scholkopf et al. <ref type="bibr" target="#b13">[14]</ref> to reject the tuple if it does not follow ξ. Moreover, it models the quality evaluation as hypothesis testing and rejects the samples that have a higher chance of being labeled as ªunrealisticº by a random human evaluator. Finally, to minimize the number of queries to the foundation model, we provide a guide tuple (and a mask), in addition to the prompt, to the foundation model. We model the guide-selection problem as contextual multi-armed bandit and propose a solution based on the contextual UCB for it.</p><p>Before concluding this section, let us provide some experiment results to demonstrate the effectiveness of data augmentation with CHAMELEON. We use FERET DB <ref type="bibr" target="#b14">[15]</ref> for this experiment, which comprises 1199 individual images and serves as a standardized facial image database for researchers to develop algorithms and report results. All images in FERET DB share the same dimensions, pose, and facial expression. First, we identified the (level-1) uncovered ethnicity groups, using the threshold 80. We then used CHAMELEON and resolved the lack of coverage </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Generating Reliability Warnings</head><p>Interpretability is a necessity for data scientists who develop predictive models for critical decision-making. In such settings, it is important to provide additional means to support the following question: is an individual prediction of the model reliable for decision-making? Our goal is to use the lack of representation to help decision-makers find insights about this critical question. To further motivate this, let us use the following example:</p><p>Example 1: (Part1): Consider a judge who needs to decide whether to accept or deny a bail request. Using data-driven predictive models is prevalent in such cases for predicting recidivism <ref type="bibr" target="#b15">[16]</ref>. Indeed, such models can be beneficial to help the judge make wise decisions. Suppose the model predicts the queried individual as high risk (or low risk). The judge is aware and concerned about the critics surrounding such models. A major question the judge faces is whether or not they should rely on the prediction outcome to take action for this case. Furthermore, if, for instance, they decide to ignore the outcome and hence they need to provide a statement supporting their action, what evidence can they provide?</p><p>In line with the recent trend on data-centric AI <ref type="bibr" target="#b16">[17]</ref>, we design novel approaches, complimentary to the existing work on trustworthy AI [18±21], to address the aforementioned trust question through the lens of data. In particular, unlike existing works that generate trust information from a given model, we associate data sets with proper measurements that specify their the scope of use for predicting future cases. We note that a predictive model provides only probabilistic guarantees on the average loss over the distribution represented by the data set used for training it. As a result, these predictions may not be distribution generalizable <ref type="bibr" target="#b21">[22]</ref>. Consequently, if the query point is not represented by the data, the guarantees may not hold, hence one cannot rely on the prediction outcome. Besides, an essential requirement for a learning algorithm is that its training data D should represent the underlying distribution ξ. Even if so, the trained model h only provides a probabilistic guarantee on the expected loss on random samples from ξ. A model that performs well on majority of samples drawn from ξ will have a high performance on average. Still, as we observed in Figure <ref type="figure" target="#fig_3">4</ref>, its performance for minorities and points that are not represented is questionable. Let us consider the following toy example:</p><p>Example 2: Consider a binary classification task where the input space is x = ⟨x 1 , x 2 ⟩ and the output space is the binary label y with values {-1 (red) , +1 (blue)}. Suppose the underlying data distribution ξ follows a 2D Gaussian, where x 1 and x 2 are positively correlated as shown in Figure <ref type="figure">6</ref>. The figure shows the data set D drawn independently from the distribution ξ, along with their labels as their colors. Using D, the prediction model h is constructed as shown in Figure <ref type="figure">7</ref>. The decision boundary is specified in the picture; while any point above the line is predicted as +1, a query point below it is labeled as -1. The classifier has been evaluated using a test set that is an iid sample set drawn from the underlying data set ξ. The accuracy on the test set is high (above 90%), and hence, the model gets deployed. We cherry-picked four query points, q 1 to q 4 , that are also included in Figure <ref type="figure">7</ref>. Using h for prediction, h(q 1 ) = -1, h(q 2 ) = +1, h(q 3 ) = +1, and h(q 4 ) = -1. Figure <ref type="figure" target="#fig_6">8</ref> adds the ground-truth boundary to the search space, revealing the true label of the query points: every point inside the red circle has the true label -1 while any point outside of it is +1. Looking at the figure, y 1 = +1 while the model predicted it as h(q 1 ) = -1. □</p><p>Let us take a closer look at the four query points in this example and their placement with regard to the tuples in D used for training h. q 2 belongs to a dense region with many training tuples in D surrounding it. Besides, all of the tuples in its vicinity have the same label y = +1. As a result, one can expect that the model's outcome h(q 2 ) = +1 should be a reliable prediction. Similar to q 2 , q 4 also belongs to a dense region in D; however, q 4 belongs to an uncertain region, where some of the tuples in its vicinity have a label y = +1, and some others have the label y = -1. Considering the uncertainty in the vicinity of q 4 , one cannot confidently rely on the outcome of the model h. On the other hand, the neighbors of q 1 (resp. q 3 ) are not uncertain, all having the label y = -1 (resp. y = +1). However, the query points q 1 and q 3 are not well represented by D. In other words, q 1 and q 3 are unlikely to be generated according to the underlying distribution ξ, represented by D. As a result, following the no-free-lunch theorem <ref type="bibr" target="#b22">[23]</ref>, one cannot expect the outcome of model h to be reliable for these points. Looking at the ground-truth boundary in Figure <ref type="figure" target="#fig_6">8</ref>, h luckily predicted the outcome for q 3 correctly, but it was not fortunate to predict the y 1 correctly. Nevertheless, since the model is not reliably trained for these points, its outcome for these query points is not trustworthy.</p><p>From Example 2, we observe that the outcome of a model h, trained using a data set D is not reliable for a query point q, if:</p><p>• Lack of representation: q is not well-represented by D. In such cases, the model has not seen ªenoughº samples similar to q to reliably learn and predict the outcome of q.</p><p>• Lack of certainty: q belongs to an uncertain region, where different tuples of D in the vicinity of q have different target values. q belongs to a high-fluctuating area, where tuples in the vicinity of q have a wide range of values.</p><p>Based on these two observations, we propose Representation-and-Uncertainty (RU) measures. To identify if a Figure 7: The decision boundary of learned model h and query points q 1 to q 4 query suffers from uncertainty or lack of representation, one could use a deterministic approach using a fixed threshold. Then if the number of similar samples to (resp. label fluctuation in vicinity of) q is larger than the threshold it is considered as unrepresented (resp. uncertain). This approach, however, would be misleading since two numbers close to the threshold could be treated very differently. Also, all points on each side of the threshold would be considered equally represented (resp., certain). Instead, we consider a randomized approach, widely popular in the literature, including <ref type="bibr" target="#b23">[24]</ref>. That is, instead of using fixed thresholds, a Bernoulli variable (a biased coin) is used that assigns q as unrepresented (resp., uncertain) based on the number of samples similar to it (resp., its neighborhood uncertainty). Given a query point q, let P o be the probability indicating if q is not represented and let P u be the probability indicating if q belongs to an uncertain region. We represent the probability of the Bernoulli variables for lack of representation or uncertainty components as P o and P u , respectively. Note that the two Bernoulli variables P o and P u are independent from each other. That simply follows the argument that after specifying the number of similar samples to q whether or not it should be considered as unrepresented does not depend on the uncertainty in the neighborhood of q.</p><p>Definition 4.1 (STRONGRU) The STRONGRU is a probabilistic measure that considers the outcome of a model for a query point q untrustworthy if q is not represented by D and it belongs to an uncertain region. Formally, the STRONGRU measure is: SRU (q) = P (q is outlier) ∧ (q belongs to uncertain region)</p><p>Since P o and P u are independent:</p><formula xml:id="formula_1">SRU (q) = P o (q) × P u (q)<label>(1)</label></formula><p>STRONGRU raises the warning signal only when the query point fails on both conditions of being represented by D and not belonging to an uncertain region. For instance, in Example 2 none of the query points fail both on representation and on uncertainty; hence neither has a high STRONGRU score. On the other hand, a high STRONGRU score for a query point q provides a strong warning signal that one should perhaps reject the model outcome and not consider it for decision-making.</p><p>STRONGRU is a strong signal that raises warnings only for the fearfully concerning cases that fail both on representation and uncertainty. However, as observed in Example 2 a query points failing at least one of these conditions may also not be reliable, at least for critical decision making. We define the WEAKRU measure to raise a warning for such cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 4.2 (WEAKRU)</head><p>The WEAKRU measure is a probabilistic measure that considers the outcome of a model for a query point q untrustworthy if q is not represented by D or it belongs to an uncertain region. Formally, the WEAKRU is computed as: W RU (q) = P (q is outlier) ∨ (q belongs to uncertain region) = P o (q) + P u (q) -P o (q) × P u (q) (2) Proposing quantitative probabilistic outcomes, RU measures are interpretable for the users, since beyond the scores, the uncertainty and lack of representation components provide an explanation to justify them. Please refer to <ref type="bibr" target="#b24">[25]</ref> for more details on how to efficiently and effectively compute the representation (P o ) and uncertainty (P u ) probabilities, using only D. In Example 1, let us see how the RU measures can be helpful. Example 1. (part 2): RU measures raise warning when the fitness of the data set used for drawing a prediction is questionable, helping the judge to be cautious when taking action. Besides, these measures provide quantitative evidence to support the judge's action when they decide to ignore a prediction outcome that is not trustworthy. The judge, for example, can argue to ignore a model outcome for a specific case, based on the insight that the model has been built using a data set that fails to represent the given case. □ Finally, let us demonstrate the efficacy of RU measures through a series of experiments. Since the RU measures are data-centric, those are applicable for both classification and regression tasks, irrespective of the 0 . 0 -0 . 1 0 . 1 -0 . 2 0 . 2 -0 . 3 0 . 3 -0 . 4 0 . 4 -0 . 5 0 . 5 -0 . 6 0 . 6 -0 . 7 0 . 7 -0 . 8 0 . 8 -0 . 9 0 . 9 -1 . 0 WeakRU 0 0.2 0.4 0.6 0.8 1 Accuracy FPR Figure 10: Adult, efficacy of WEAKRU on classification 0 . 0 -0 . 1 0 . 1 -0 . 2 0 . 2 -0 . 3 0 . 3 -0 . 4 0 . 4 -0 . 5 0 . 5 -0 . 6 0 . 6 -0 . 7 0 . 7 -0 . 8 StrongRU 0 2 4 6 8 10 11 RSS Figure 11: House Sales in King County, efficacy of STRONGRU on regression 0 . 0 -0 . 1 0 . 1 -0 . 2 0 . 2 -0 . 3 0 . 3 -0 . 4 0 . 4 -0 . 5 0 . 5 -0 . 6 0 . 6 -0 . 7 0 . 7 -0 . 8 0 . 8 -0 . 9 0 . 9 -1 . 0 WeakRU 0 1 2 3 4 5 10 11 RSS Figure 12: House Sales in King County, efficacy WEAKRU on regression model used. We use Adult dataset [26] for classification and House Sales in King County dataset for the validation of regression tasks. From each dataset, we uniformly sample two sets from the underlying distribution. The first set serves as the training set to compute the RU values, and the second one is used as the test set from which the queries are drawn. We validate our proposal by providing the correlation between the RU values and the performance of an ML model's prediction on the same data.</p><p>We start by computing the RU values for all the query points in the test set. Next, we bucketize the query points based on their RU values in equi-width buckets of width 0.1. We repeat this for both STRONGRU and WEAKRU measures. Next, we train a model on the training data set and predict the target variable for the points in each range of RU measure. The validation results for the classification task on the Adult dataset are presented in Figures <ref type="figure">9</ref> and <ref type="figure" target="#fig_0">10</ref>. Each figure corresponds to the accuracy/error measures of the classifier over each bucket of RU values for STRONGRU and WEAKRU. As the RU values increase, the accuracy of the model drops while the FPR rises, and therefore, the model fails to capture the ground truth for the points that fall into untrustworthy regions in the data set. By repeating the aforementioned steps for the regression task on the House Sales in King County dataset, we observe similar results presented in Figures <ref type="figure" target="#fig_0">11</ref> and <ref type="figure" target="#fig_1">12</ref>. As the RU value increases, the RSS of the regression model follows the same trend denoting that the model fails to perform for tuples with a high RU value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Bias in data has been looked at for a long time in statistical community <ref type="bibr" target="#b26">[27]</ref> but social data presents different challenges [28±32]. The diversity and representativeness of data have been widely studied <ref type="bibr" target="#b31">[32]</ref>, in fields such as social science [33±35], political science <ref type="bibr" target="#b35">[36]</ref>, and information retrieval <ref type="bibr" target="#b36">[37]</ref>. Tracing back machine bias to its source, there have been major efforts to identify different types <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39]</ref> and sources [40±42] of biases in data. Efforts to satisfy responsible data requirements <ref type="bibr" target="#b5">[6]</ref> extend to various stages of the data analysis pipeline, including data annotation <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b43">44]</ref>, data cleaning and repair [45±47], data imputation <ref type="bibr" target="#b47">[48]</ref>, entity resolution <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b49">50]</ref>, data integration <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>, etc.</p><p>Data Coverage: The notion of data coverage has received extensive attention from different angles. Detecting lack of coverage has been studied for datasets with discrete <ref type="bibr" target="#b0">[1]</ref> and continuous <ref type="bibr" target="#b2">[3]</ref> attributes populated in single or multiple <ref type="bibr" target="#b50">[51]</ref> relations. To resolve insufficient coverage, [52±54] consider resolving representation bias in preprocessing pipelines by rewriting queries into the closest operation so that certain subgroups are sufficiently represented in the downstream tasks. Alternatively, <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b54">55]</ref> propose a data collection strategy to acquire as little additional data as possible (to minimize the associated costs) to meet the representation constraints. <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10]</ref> opt for a data augmentation approach by adding partially altered duplicates of already existing tuples or generating new synthetic entries from existing data. Consequently, the new data set has an equal number of elements for different groups, resulting in potentially resolving the under-representation issues. Finally, <ref type="bibr" target="#b4">[5]</ref> utilizes data integration techniques to consolidate data from different sources into a single dataset to resolve representation bias. Related works also include [55±57] that seek to understand if the overall performance of the model fails to reflect and performs poorly on certain slices in the data. As alternative approaches to measure representation bias, the notion of representation rate <ref type="bibr" target="#b9">[10]</ref> (a.k.a. equal base rate <ref type="bibr" target="#b57">[58]</ref>) is introduced which compared with coverage, it is more restrictive as it requires almost equal ratios from different groups. Please refer to <ref type="bibr" target="#b1">[2]</ref> for a comprehensive survey about representation bias in data.</p><p>ML Reliability: Model-centric works for uncertainty quantification such as probabilistic classifiers [59±62], prediction intervals (PIs) [63±65] and conformal predictions (CP) <ref type="bibr" target="#b65">[66,</ref><ref type="bibr" target="#b66">67]</ref> that are used for measuring prediction uncertainty, are built by maximizing the expected performance on random sample from the underlying distribution. As a result, while providing accurate estimations for the dense regions of data (e.g. majority groups), their estimation accuracy is questionable for the poorly represented regions. In particular, <ref type="bibr" target="#b65">[66]</ref> recognizes the lack of guarantees in the performance of CP for such regions. Besides, the bulk of work on trustworthy AI provides information that supports the outcome of an ML model. For example, existing work on explainable AI, including [68±70], aims to find simple explanations and rules that justify the outcome of a model. Conversely, we aim to raise warning signals when the outcome of a model is not trustworthy. That is, to provide reasons that cast doubt on the reliability of the model outcome for a given query point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Final Remarks</head><p>As Data-centric AI and Responsible AI emerge as focal points in data science research, the development of Data-centric methodologies for ensuring Responsible and Trustworthy AI attracts increasing attention. While there is some excellent work on responsible data management to achieve this goal, there remain many challenges yet to be addressed.</p><p>In this paper, we focused on a crucial aspect of responsible data ± detecting and addressing the underrepresentation of minorities within a data set. We formally defined the notion of data coverage and discussed various techniques for (a) identifying lack of representation issues across different data modalities, (b) ensuring proper representation of minorities in data, and (c) limiting the scope-of-use of data sets based on their representation issues by generating proper (RU) warning signals. Even though the research on detecting lack of coverage issues is relatively mature, resolution techniques are still understudied. Considering the recent advancements in Generative AI, utilizing Foundation Models and Large Language Models, and studying their limitations, for data augmentation to improve the representation of minorities at the data level seems interesting to further explore.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Categorical attributes: the uncovered region of a toy example, as the collection of three MUPs.</figDesc><graphic coords="4,54.00,107.54,150.66,111.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Continuous attributes, 2D: identifying the covered region in the gray Voronoi cell.</figDesc><graphic coords="4,220.31,74.41,150.65,145.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Continuous attributes, 2D: Uncovered region marked in red.</figDesc><graphic coords="4,386.61,72.00,150.65,147.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure4: ML models' low performance for females in the presence of representation bias.<ref type="bibr" target="#b3">[4]</ref> </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Architecture of CHAMELEON for image data augmentation for coverage enhancement.</figDesc><graphic coords="7,72.00,350.33,218.68,240.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :Figure 7 :</head><label>67</label><figDesc>Figure 6: Data set D generated using a Gaussian distribution; x 1 and x 2 are positively correlated</figDesc><graphic coords="9,72.00,543.66,155.53,155.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Ground-truth boundary, overlaid on the model decision boundary and query points</figDesc><graphic coords="9,399.75,543.66,155.53,155.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 10 :Figure 12 :</head><label>1012</label><figDesc>Figure 9: Adult, efficacy of STRONGRU on classification</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Illustrating the effect of lack of coverage repair using CHAMELEON on FERTDBTo evaluate the effectiveness of the system, we trained a CNN model to predict the race of each image within this dataset. We then retrained the identical CNN on the repaired training data. Importantly, our test dataset for both experiments remains consistent and is derived from real images. Table1presents the improvements in precision, recall, and F1 score metrics for under-represented groups after repairing the dataset. The results indicate an enhancement in performance metrics for all under-represented groups following the repair process.</figDesc><table><row><cell></cell><cell cols="4">Classifier Performance on FERTDB</cell><cell cols="4">Classifier Performance on Repaired</cell></row><row><cell cols="9">Ethnicity Groups #Images Precision Recall F1-Score #Images Precision Recall F1-Score</cell></row><row><cell>Overall</cell><cell>756</cell><cell>0.81</cell><cell>0.75</cell><cell>0.78</cell><cell>987</cell><cell>0.70</cell><cell>0.75</cell><cell>0.72</cell></row><row><cell>Black</cell><cell>40</cell><cell>0.19</cell><cell>0.22</cell><cell>0.16</cell><cell>100</cell><cell>0.48</cell><cell>0.56</cell><cell>0.52</cell></row><row><cell>Hispanic</cell><cell>19</cell><cell>0.50</cell><cell>0.17</cell><cell>0.25</cell><cell>100</cell><cell>0.62</cell><cell>0.36</cell><cell>0.45</cell></row><row><cell>Middle Eastern</cell><cell>10</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>100</cell><cell>0.20</cell><cell>0.41</cell><cell>0.27</cell></row><row><cell>issues.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://openai.com/dall-e-2</p></note>
		</body>
		<back>

			<div type="funding">
<div><p>* This research was supported by the <rs type="funder">National Science Foundation</rs> under grant No. <rs type="grantNumber">2107290</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_agFhPmF">
					<idno type="grant-number">2107290</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Assessing and remedying coverage for a given dataset</title>
		<author>
			<persName><forename type="first">A</forename><surname>Asudeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jagadish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="554" to="565" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Representation bias in data: A survey on identification and resolution techniques</title>
		<author>
			<persName><forename type="first">N</forename><surname>Shahbazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Asudeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jagadish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Identifying insufficient data coverage for ordinal continuous-valued attributes</title>
		<author>
			<persName><forename type="first">A</forename><surname>Asudeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shahbazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Jagadish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD. ACM</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Data coverage for detecting representation bias in image datasets: A crowdsourcing approach</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mousavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shahbazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Asudeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EDBT</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="47" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Tailoring data source distributions for fairness-aware data integration</title>
		<author>
			<persName><forename type="first">F</forename><surname>Nargesian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Asudeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jagadish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="2519" to="2532" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Responsible data integration: Next-generation challenges</title>
		<author>
			<persName><forename type="first">F</forename><surname>Nargesian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Asudeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Jagadish</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>SIGMOD</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Data augmentation for discrimination prevention and bias disambiguation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Ríos Aliaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bouneffouf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Muthusamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Varshney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIES</title>
		<imprint>
			<biblScope unit="volume">358</biblScope>
			<biblScope unit="page">364</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">SMOTE: synthetic minority over-sampling technique</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Bowyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">O</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">P</forename><surname>Kegelmeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Intell. Res</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="321" to="357" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Dealing with bias via data augmentation in supervised learning scenarios</title>
		<author>
			<persName><forename type="first">V</forename><surname>Iosifidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ntoutsi</surname></persName>
		</author>
		<editor>Jo Bates Paul D. Clough Robert Jäschke</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Data preprocessing to mitigate bias: A maximum entropy based approach</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Celis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Keswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Vishnoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1349" to="1359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Towards distribution-aware query answering in data markets</title>
		<author>
			<persName><forename type="first">A</forename><surname>Asudeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Nargesian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="3137" to="3144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Randomized algorithms</title>
		<author>
			<persName><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Erfanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Asudeh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.01071</idno>
		<title level="m">Chameleon: Foundation models for fairness-aware multi-modal data augmentation to enhance coverage of minorities</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Support vector method for novelty detection</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The feret database and evaluation procedure for face-recognition algorithms</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wechsler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Rauss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and vision computing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="295" to="306" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The accuracy, fairness, and limits of predicting recidivism</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dressel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Farid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science advances</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">5580</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Mlops: From model-centric to data-centric AI</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Trustworthy AI</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Wing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CACM</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="64" to="71" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Analysis of trustworthiness in machine learning and deep learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kentour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>InfoComp</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Trustworthy AI: A computational perspective</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.06641</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Trustworthy AI</title>
		<author>
			<persName><forename type="first">R</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vatsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ratha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th ACM IKDD CODS and 26th COMAD</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="449" to="453" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">What you see is what you get: Distributional generalization for algorithm design in deep learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kulynych</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Błasiok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nakkiran</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.03230</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Kakade</surname></persName>
		</author>
		<title level="m">On the sample complexity of reinforcement learning</title>
		<meeting><address><addrLine>United Kingdom</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>University of London, University College London</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Fairness through awareness</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pitassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Reingold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ITCS</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="214" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Data-centric reliability evaluation of individual predictions</title>
		<author>
			<persName><forename type="first">N</forename><surname>Shahbazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Asudeh</surname></persName>
		</author>
		<idno>CoRR, abs/2204.07682</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Lichman</surname></persName>
		</author>
		<ptr target="https://archive.ics.uci.edu/ml/datasets/adult" />
		<title level="m">Adult income dataset, UCI machine learning repository</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Contributions to the theory of testing statistical hypotheses</title>
		<author>
			<persName><forename type="first">J</forename><surname>Neyman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Pearson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Research Memoirs</title>
		<imprint>
			<date type="published" when="1936">1936</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Social data: Biases, methodological pitfalls, and ethical boundaries</title>
		<author>
			<persName><forename type="first">A</forename><surname>Olteanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kiciman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Big Data</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Fairness and machine learning: Limitations and opportunities</title>
		<author>
			<persName><forename type="first">S</forename><surname>Barocas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Narayanan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>fairmlbook. org</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Big data&apos;s disparate impact</title>
		<author>
			<persName><forename type="first">S</forename><surname>Barocas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Selbst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Calif. L. Rev</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page">671</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Fairness, rankings, and behavioral biases</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">FAT*</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Diversity in big data: A review</title>
		<author>
			<persName><forename type="first">M</forename><surname>Drosou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pitoura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stoyanovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Big data</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="73" to="84" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Berrey</surname></persName>
		</author>
		<title level="m">The enigma of diversity: The language of race and the limits of racial justice</title>
		<imprint>
			<publisher>University of Chicago Press</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Why diversity programs fail and what works better</title>
		<author>
			<persName><forename type="first">F</forename><surname>Dobbin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kalev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Harvard Business Review</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">7-8</biblScope>
			<biblScope unit="page" from="52" to="60" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Measurement of diversity</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Simpson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">163</biblScope>
			<biblScope unit="issue">4148</biblScope>
			<date type="published" when="1949">1949</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">The wisdom of crowds</title>
		<author>
			<persName><forename type="first">J</forename><surname>Surowiecki</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Anchor</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Diversifying search results</title>
		<author>
			<persName><forename type="first">R</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gollapudi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Halverson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ieong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="5" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A survey on bias and fairness in machine learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mehrabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Morstatter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Galstyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Bias in computer systems</title>
		<author>
			<persName><forename type="first">B</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nissenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TOIS</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="330" to="347" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Unbiased look at dataset bias</title>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2011</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1521" to="1528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The hidden biases in big data</title>
		<author>
			<persName><forename type="first">K</forename><surname>Crawford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Harvard business review</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Algorithmic accountability: Journalistic investigation of computational power structures</title>
		<author>
			<persName><forename type="first">N</forename><surname>Diakopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital journalism</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="398" to="415" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Towards fair truth discovery from biased crowdsourced answers</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">599</biblScope>
			<biblScope unit="page">607</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Fairness and bias in truth discovery algorithms: An experimental analysis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lazier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thirumuruganathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Anahideh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.12573</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Interventional fairness: Causal database repair for algorithmic fairness</title>
		<author>
			<persName><forename type="first">B</forename><surname>Salimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Suciu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="793" to="810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Data cleaning for accurate, fair, and robust models: A big data-AI integration approach</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Tae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Roh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Whang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DEEM workshop</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Database repair meets algorithmic fairness</title>
		<author>
			<persName><forename type="first">B</forename><surname>Salimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Suciu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMOD Record</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="34" to="41" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Martínez-Plumed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ferri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nieves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hernández-Orallo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.12728</idno>
		<title level="m">Fairness and missing values</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Through the fairness lens: Experimental analysis and evaluation of entity matching</title>
		<author>
			<persName><forename type="first">N</forename><surname>Shahbazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Danevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Nargesian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Asudeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="3279" to="3292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Fairer demo: Fairness-aware and explainable entity resolution</title>
		<author>
			<persName><forename type="first">N</forename><surname>Fanourakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kontousias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Efthymiou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Christophides</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Plexousakis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Identifying insufficient data coverage in databases with multiple relations</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Asudeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jagadish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="2229" to="2242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Coverage-based rewriting for data preparation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Accinelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Minisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Catania</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EDBT Workshops</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">The impact of rewriting on coverage constraint satisfaction</title>
		<author>
			<persName><forename type="first">C</forename><surname>Accinelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Catania</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Guerrini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Minisi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EDBT Workshops</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Fairness-aware range queries for selecting unbiased data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shetiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">P</forename><surname>Swift</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Asudeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE. IEEE</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Slice tuner: A selective data acquisition framework for accurate and fair machine learning models</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Tae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Whang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1771" to="1783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Slice finder: Automated data slicing for model validation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kraska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Polyzotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Tae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Whang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1550" to="1553" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Sliceline: Fast, linear-algebra-based slice finding for ml model debugging</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sagadeeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Boehm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2021">2290. 2021</date>
			<biblScope unit="page">2299</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mullainathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Raghavan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.05807</idno>
		<title level="m">Inherent trade-offs in the fair determination of risk scores</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Obtaining calibrated probability estimates from decision trees and naive bayesian classifiers</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zadrozny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Elkan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="609" to="616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Transforming classifier scores into accurate multiclass probability estimates</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zadrozny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Elkan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="694" to="699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods</title>
		<author>
			<persName><forename type="first">J</forename><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in large margin classifiers</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="61" to="74" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Predicting good probabilities with supervised learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Niculescu-Mizil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd international conference on Machine learning</title>
		<meeting>the 22nd international conference on Machine learning</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="625" to="632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Prediction intervals</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chatfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Business and Economic Statistics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="121" to="135" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">High-quality prediction intervals for deep learning: A distribution-free, ensembled approach</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pearce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Brintrup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neely</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4075" to="4084" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Lower upper bound estimation method for construction of neural network-based prediction intervals</title>
		<author>
			<persName><forename type="first">A</forename><surname>Khosravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nahavandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Creighton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Atiya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on neural networks</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="337" to="346" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Angelopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bates</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.07511</idno>
		<title level="m">A gentle introduction to conformal prediction and distribution-free uncertainty quantification</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">A tutorial on conformal prediction</title>
		<author>
			<persName><forename type="first">G</forename><surname>Shafer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vovk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Causal learning and explanation of deep neural networks via autoencoded activations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Harradon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Druce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ruttenberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.00541</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">why should i trust you?&quot; explaining the predictions of any classifier</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1135" to="1144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Darpa&apos;s explainable artificial intelligence (XAI) program</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gunning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Aha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="44" to="58" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
